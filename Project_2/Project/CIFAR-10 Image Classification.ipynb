{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92428a7",
   "metadata": {},
   "source": [
    "### Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0474400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fe883",
   "metadata": {},
   "source": [
    "### Data extraction and setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5156f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_setup_data(zip_path, extract_path):\n",
    "    \"\"\"\n",
    "    Extract CIFAR-10 dataset from ZIP file and set up directory structure\n",
    "    \n",
    "    Parameters:\n",
    "    zip_path (str): Path to CIFAR-10 ZIP file\n",
    "    extract_path (str): Path where to extract the data\n",
    "    \n",
    "    Returns:\n",
    "    str: Path to extracted data\n",
    "    \"\"\"\n",
    "    print(\"EXTRACTING DATASET\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Extract ZIP file\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        \n",
    "        filenames = os.listdir(extract_path)\n",
    "        print(f\"Dataset extracted successfully\")\n",
    "        print(f\"Total files: {len(filenames)}\")\n",
    "        print(f\"Sample files: {filenames[:5]}\")\n",
    "        \n",
    "        return extract_path\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"ZIP file not found. Using alternative data loading...\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "735cce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_labels(extract_path):\n",
    "    \"\"\"\n",
    "    Load and explore the CIFAR-10 labels\n",
    "    \n",
    "    Parameters:\n",
    "    extract_path (str): Path to extracted dataset\n",
    "    \n",
    "    Returns:\n",
    "    tuple: DataFrame with labels and processed labels list\n",
    "    \"\"\"\n",
    "    print(f\"\\nLOADING AND EXPLORING LABELS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Load labels CSV file\n",
    "        labels_df = pd.read_csv(os.path.join(extract_path, 'trainlabels.csv'))\n",
    "        \n",
    "        print(f\"Labels loaded: {labels_df.shape[0]} samples\")\n",
    "        print(f\"Label distribution:\")\n",
    "        \n",
    "        label_counts = labels_df['label'].value_counts()\n",
    "        for label, count in label_counts.items():\n",
    "            print(f\"   - {label}: {count} images\")\n",
    "        \n",
    "        # Create label dictionary for encoding\n",
    "        labels_dictionary = {\n",
    "            'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "            'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
    "        }\n",
    "        \n",
    "        # Convert labels to numerical format\n",
    "        labels = [labels_dictionary[label] for label in labels_df['label']]\n",
    "        \n",
    "        print(f\"Labels encoded to numerical format\")\n",
    "        print(f\"Sample encoded labels: {labels[:5]}\")\n",
    "        \n",
    "        return labels_df, labels, labels_dictionary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading labels: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfe980cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_images(extract_path, labels_df):\n",
    "    \"\"\"\n",
    "    Load and process CIFAR-10 images\n",
    "    \n",
    "    Parameters:\n",
    "    extract_path (str): Path to extracted dataset\n",
    "    labels_df (DataFrame): DataFrame containing image IDs\n",
    "    \n",
    "    Returns:\n",
    "    list: Processed image data as numpy arrays\n",
    "    \"\"\"\n",
    "    print(f\"\\nLOADING AND PROCESSING IMAGES\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        id_list = list(labels_df['id'])\n",
    "        train_data_folder = os.path.join(extract_path, 'train')\n",
    "        \n",
    "        data = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        print(f\"Processing {len(id_list)} images...\")\n",
    "        \n",
    "        for i, img_id in enumerate(id_list):\n",
    "            try:\n",
    "                img_path = os.path.join(train_data_folder, f\"{img_id}.png\")\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "                data.append(img_array)\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress indicator\n",
    "                if (i + 1) % 10000 == 0:\n",
    "                    print(f\"   Processed {i + 1}/{len(id_list)} images...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   Warning: Could not process image {img_id}: {e}\")\n",
    "        \n",
    "        print(f\"Successfully processed: {processed_count} images\")\n",
    "        print(f\"Image shape: {data[0].shape if data else 'N/A'}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing images: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f8e03",
   "metadata": {},
   "source": [
    "### Data paths configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1500711",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_PATH = r'C:\\Users\\Mohamed Makki\\Desktop\\cifar-10.zip'\n",
    "EXTRACT_PATH = r'C:\\Users\\Mohamed Makki\\Desktop\\cifar-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d894028",
   "metadata": {},
   "source": [
    "### Load data or use alternative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f567d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTING DATASET\n",
      "------------------------------\n",
      "Dataset extracted successfully\n",
      "Total files: 6\n",
      "Sample files: ['sampleSubmission.csv', 'test', 'test.7z', 'train', 'train.7z']\n",
      "\n",
      "LOADING AND EXPLORING LABELS\n",
      "------------------------------\n",
      "Labels loaded: 50000 samples\n",
      "Label distribution:\n",
      "   - frog: 5000 images\n",
      "   - truck: 5000 images\n",
      "   - deer: 5000 images\n",
      "   - automobile: 5000 images\n",
      "   - bird: 5000 images\n",
      "   - horse: 5000 images\n",
      "   - ship: 5000 images\n",
      "   - cat: 5000 images\n",
      "   - dog: 5000 images\n",
      "   - airplane: 5000 images\n",
      "Labels encoded to numerical format\n",
      "Sample encoded labels: [6, 9, 9, 4, 1]\n",
      "\n",
      "LOADING AND PROCESSING IMAGES\n",
      "------------------------------\n",
      "Processing 50000 images...\n",
      "   Processed 10000/50000 images...\n",
      "   Processed 20000/50000 images...\n",
      "   Processed 30000/50000 images...\n",
      "   Processed 40000/50000 images...\n",
      "   Processed 50000/50000 images...\n",
      "Successfully processed: 50000 images\n",
      "Image shape: (32, 32, 3)\n",
      "\n",
      "REAL DATA LOADED\n",
      "Images shape: (50000, 32, 32, 3)\n",
      "Labels shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try to extract and load real data\n",
    "    extracted_path = extract_and_setup_data(ZIP_PATH, EXTRACT_PATH)\n",
    "    \n",
    "    if extracted_path:\n",
    "        labels_df, labels, labels_dict = load_and_explore_labels(extracted_path)\n",
    "        image_data = load_and_process_images(extracted_path, labels_df)\n",
    "        \n",
    "        if image_data and labels:\n",
    "            X = np.array(image_data)\n",
    "            y = np.array(labels)\n",
    "            print(f\"\\nREAL DATA LOADED\")\n",
    "            print(f\"Images shape: {X.shape}\")\n",
    "            print(f\"Labels shape: {y.shape}\")\n",
    "        else:\n",
    "            raise Exception(\"Failed to process real data\")\n",
    "    else:\n",
    "        raise Exception(\"Failed to extract data\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nCREATING SAMPLE DATA\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Note: {e}\")\n",
    "    print(\"Using synthetic CIFAR-10 like data for demonstration...\")\n",
    "    \n",
    "    # Create sample data that matches CIFAR-10 structure\n",
    "    X = np.random.randint(0, 255, (5000, 32, 32, 3), dtype=np.uint8)\n",
    "    y = np.random.randint(0, 10, 5000)\n",
    "    \n",
    "    labels_dict = {\n",
    "        'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "        'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
    "    }\n",
    "    \n",
    "    print(f\"Sample data created: {X.shape}, {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e0eb4",
   "metadata": {},
   "source": [
    "### Data preprocessing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ccb18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 40000 images\n",
      "Testing set: 10000 images\n",
      "Pixel values normalized to [0, 1] range\n",
      "Input shape: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Normalize pixel values to 0-1 range\n",
    "X_train_scaled = X_train.astype('float32') / 255.0\n",
    "X_test_scaled = X_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Training set: {X_train_scaled.shape[0]} images\")\n",
    "print(f\"Testing set: {X_test_scaled.shape[0]} images\")\n",
    "print(f\"Pixel values normalized to [0, 1] range\")\n",
    "print(f\"Input shape: {X_train_scaled.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5125b77",
   "metadata": {},
   "source": [
    "### Build transfer learning model with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "754c7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    Create transfer learning model using ResNet50\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): Shape of input images\n",
    "    num_classes (int): Number of output classes\n",
    "    \n",
    "    Returns:\n",
    "    keras.Sequential: Compiled transfer learning model\n",
    "    \"\"\"\n",
    "    print(f\"\\nBUILDING TRANSFER LEARNING MODEL\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Load pre-trained ResNet50 (without top layers)\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(256, 256, 3)  # ResNet50 requires larger input\n",
    "    )\n",
    "    \n",
    "    print(f\"ResNet50 base model loaded\")\n",
    "    print(f\"Base model parameters: {base_model.count_params():,}\")\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build complete model\n",
    "    model = models.Sequential([\n",
    "        # Upsampling layers to match ResNet50 input requirements\n",
    "        UpSampling2D((2, 2), input_shape=input_shape),  # 32x32 -> 64x64\n",
    "        UpSampling2D((2, 2)),                          # 64x64 -> 128x128\n",
    "        UpSampling2D((2, 2)),                          # 128x128 -> 256x256\n",
    "        \n",
    "        # Pre-trained ResNet50 base\n",
    "        base_model,\n",
    "        \n",
    "        # Custom classification head\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        BatchNormalization(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model with lower learning rate for transfer learning\n",
    "    model.compile(\n",
    "        optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Transfer learning model created\")\n",
    "    print(f\"Total parameters: {model.count_params():,}\")\n",
    "    print(f\"Trainable parameters: {np.sum([tf.keras.backend.count_params(p) for p in model.non_trainable_weights]):,}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a663dfa",
   "metadata": {},
   "source": [
    "### Create and train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7944907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BUILDING TRANSFER LEARNING MODEL\n",
      "------------------------------\n",
      "ResNet50 base model loaded\n",
      "Base model parameters: 23,587,712\n",
      "Transfer learning model created\n",
      "Total parameters: 40,899,018\n",
      "Trainable parameters: 23,850,240\n",
      "\n",
      "TRAINING TRANSFER LEARNING MODEL\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\reshaping\\up_sampling2d.py:72: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  21/1125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35:18\u001b[0m 2s/step - accuracy: 0.1001 - loss: 2.9564"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransfer learning model training completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Mohamed Makki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_transfer_learning_model()\n",
    "\n",
    "print(f\"\\nTRAINING TRANSFER LEARNING MODEL\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Transfer learning model training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c103e2",
   "metadata": {},
   "source": [
    "### Model evaluation and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Get training history\n",
    "final_train_accuracy = history.history['accuracy'][-1]\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e079505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training plots\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax2.set_title('Model Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9abecd",
   "metadata": {},
   "source": [
    "### Prediction system for CIFAR-10 classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1938b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cifar10_class(model, image_array, labels_dict):\n",
    "    \"\"\"\n",
    "    Predict CIFAR-10 class for a single image\n",
    "    \n",
    "    Parameters:\n",
    "    model: Trained transfer learning model\n",
    "    image_array: Input image as numpy array (32x32x3)\n",
    "    labels_dict: Dictionary mapping class names to indices\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Prediction result and confidence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        if image_array.shape != (32, 32, 3):\n",
    "            print(f\"Warning: Expected shape (32, 32, 3), got {image_array.shape}\")\n",
    "        \n",
    "        # Normalize and reshape\n",
    "        image_processed = image_array.astype('float32') / 255.0\n",
    "        image_batch = np.expand_dims(image_processed, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = model.predict(image_batch, verbose=0)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        confidence = np.max(predictions[0])\n",
    "        \n",
    "        # Get class name\n",
    "        class_names = list(labels_dict.keys())\n",
    "        predicted_class_name = class_names[predicted_class]\n",
    "        \n",
    "        return predicted_class, predicted_class_name, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"Error: {e}\", 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335e21e",
   "metadata": {},
   "source": [
    "### Test with a sample from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_test) > 0:\n",
    "    sample_idx = 0\n",
    "    sample_image = X_test[sample_idx]\n",
    "    actual_class = y_test[sample_idx]\n",
    "    \n",
    "    pred_class, pred_name, confidence = predict_cifar10_class(model, sample_image, labels_dict)\n",
    "    actual_name = list(labels_dict.keys())[actual_class]\n",
    "    \n",
    "    print(f\"\\nSample Prediction:\")\n",
    "    print(f\"Actual class: {actual_class} ({actual_name})\")\n",
    "    print(f\"Predicted class: {pred_class} ({pred_name})\")\n",
    "    print(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
    "    print(f\"Prediction {'Correct' if pred_class == actual_class else 'Incorrect'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
