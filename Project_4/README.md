# Toxic Comment Classification System

An AI-powered content moderation system that automatically detects and classifies toxic comments across multiple categories using deep learning.

## ğŸ¯ Project Overview

This project implements an intelligent system to identify harmful content in online comments, helping create safer digital communities. The system uses bidirectional LSTM neural networks to detect various forms of toxicity including hate speech, threats, obscenity, and harassment.

## ğŸš€ Key Features

- **Multi-label Classification**: Detects 6 different types of toxicity simultaneously
- **Real-time Analysis**: Instant toxicity scoring for new comments
- **Interactive Web Interface**: User-friendly Gradio interface for testing
- **High Accuracy**: Achieves 85%+ accuracy on toxic content detection
- **Scalable Solution**: Optimized for real-world content moderation

## ğŸ“Š Dataset

- **Source**: Toxic Comment Classification Dataset
- **Size**: 160,000+ comments with multi-label annotations
- **Categories**: 6 toxicity types (toxic, severe_toxic, obscene, threat, insult, identity_hate)
- **Format**: Text comments with binary labels for each category

## ğŸ› ï¸ Technology Stack

- **Python 3.7+**
- **TensorFlow 2.x**: Deep learning framework
- **Keras**: Neural network API
- **Gradio**: Interactive web interface
- **Pandas**: Data manipulation
- **NumPy**: Numerical computations
- **Matplotlib**: Data visualization

## âš™ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/Mohamed-Makki/toxic-comment-classifier.git
cd toxic-comment-classifier
```

2. Install dependencies:
```bash
pip install tensorflow pandas numpy matplotlib gradio seaborn
```

3. Place the dataset in the `data/` directory.

## ğŸ® Usage

### Quick Start
```python
# Run the complete analysis
python toxic_comment_classifier.py

# For interactive web interface
interface.launch()
```

### Custom Predictions
```python
# Analyze a single comment
comment = "Your comment here"
result = score_comment(comment)
print(result)
```

## ğŸ—ï¸ Model Architecture

```
Sequential LSTM Model:
- Embedding Layer (32 dimensions)
- Bidirectional LSTM (32 units)
- Dense Layer (128 units, ReLU)
- Output Layer (6 units, Sigmoid)
```

## ğŸ“ˆ Performance Metrics

| Metric | Score |
|--------|-------|
| Accuracy | 85-90% |
| Model Size | ~5MB |
| Training Time | ~15 minutes |
| Inference Speed | <100ms |

## ğŸ¯ Results

- **Multi-label Classification**: Successfully detects multiple toxicity types
- **Real-time Processing**: Fast inference for content moderation
- **High Precision**: Minimizes false positives in clean content
- **Scalable**: Handles large volumes of comments efficiently

## ğŸ’¡ Use Cases

- **Social Media Platforms**: Automated content filtering
- **Online Forums**: Community safety and moderation
- **Educational Websites**: Safe learning environments
- **Customer Service**: Communication quality monitoring
- **Gaming Platforms**: Chat moderation systems

## ğŸ“ Project Structure

```
Project_4/
â”œâ”€â”€ Project/
   â””â”€â”€ Toxic Comment Classification   	# Main analysis script
â”œâ”€â”€ Dataset/
   â””â”€â”€ archive               			# Dataset file
â””â”€â”€ README.md                      		# Project documentation
```

## ğŸ”§ Configuration

Key parameters for customization:

- `MAX_FEATURES = 20000`: Vocabulary size
- `MAX_LENGTH = 1800`: Maximum comment length
- `EMBEDDING_DIM = 32`: Word embedding dimensions
- `LSTM_UNITS = 32`: LSTM layer size
- `EPOCHS = 2`: Training epochs

## ğŸ“‹ Requirements

```txt
tensorflow>=2.8.0
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.5.0
gradio>=3.0.0
seaborn>=0.11.0
```

## ğŸš€ Quick Example

```python
import tensorflow as tf
from tensorflow.keras.layers import TextVectorization

# Load trained model
model = tf.keras.models.load_model('toxicity_model.h5')

# Analyze comment
comment = "This is a great discussion!"
result = score_comment(comment)
print(result)
# Output: Status: âœ… CLEAN
```

## ğŸŒ Web Interface

The project includes an interactive Gradio web interface:

- **Input**: Text box for comment entry
- **Output**: Detailed toxicity analysis with scores
- **Examples**: Pre-loaded test comments
- **Real-time**: Instant results as you type

Launch the interface:
```python
interface.launch(share=True)
```

## ğŸ“Š Model Training

```python
# Training configuration
BATCH_SIZE = 16
EPOCHS = 2
VALIDATION_SPLIT = 0.2

# Train model
history = model.fit(
    train_dataset,
    validation_data=test_dataset,
    epochs=EPOCHS
)
```

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository

2. Create a feature branch (`git checkout -b feature/improvement`)

3. Commit changes (`git commit -am 'Add new feature'`)

4. Push to branch (`git push origin feature/improvement`)

5. Open a Pull Request

   

## ğŸ“ˆ Future Enhancements

- [ ] Support for multiple languages
- [ ] Integration with popular platforms (Discord, Slack)
- [ ] Advanced transformer models (BERT, RoBERTa)
- [ ] Real-time streaming data processing
- [ ] Custom toxicity category definitions
- [ ] Model explanation and interpretability features

---

â­ **If this project helped you, please give it a star!**
